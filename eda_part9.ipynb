{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df=pd.read_csv(\"df_final_2.csv\")\n",
    "X_train = pd.read_csv('child-mind-institute-problematic-internet-use/train.csv').iloc[:, :-1]\n",
    "y_train = pd.read_csv('child-mind-institute-problematic-internet-use/train.csv').iloc[:, -1]\n",
    "X_test = pd.read_csv('child-mind-institute-problematic-internet-use/test.csv').iloc[:, :-1]\n",
    "y_test = pd.read_csv('child-mind-institute-problematic-internet-use/test.csv').iloc[:, -1]\n",
    "\n",
    "# X_train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv').iloc[:, :-1]\n",
    "# y_train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv').iloc[:, -1]\n",
    "# X_test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv').iloc[:, :-1]\n",
    "# y_test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv').iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series_data_stats = pd.read_csv('train_series_data_stats.csv')\n",
    "test_series_data_stats = pd.read_csv('test_series_data_stats.csv')\n",
    "\n",
    "# train_series_data_stats = pd.read_csv('/kaggle/input/series-data-v2/train_series_data_stats.csv')\n",
    "# test_series_data_stats = pd.read_csv('/kaggle/input/series-data-v2/test_series_data_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "def get_aggregations(df, column_groupby, column_agg):\n",
    "\n",
    "    if not isinstance(column_agg, list):\n",
    "        column_agg = [column_agg]\n",
    "    \n",
    "    # Create the aggregation dictionary\n",
    "    aggregation_dict = {}\n",
    "    for col in column_agg:\n",
    "        aggregation_dict.update({\n",
    "            f'Median_{col}': (col, 'median'),\n",
    "            f'Max_{col}': (col, 'max'),\n",
    "            f'Min_{col}': (col, 'min'),\n",
    "            f'Sum_{col}': (col, 'sum'),\n",
    "            f'Std_{col}': (col, 'std'),\n",
    "            f'Mean_{col}': (col, 'mean')\n",
    "        })\n",
    "    \n",
    "    # Perform groupby and aggregation\n",
    "    df_agg = df.groupby(column_groupby).agg(**aggregation_dict).reset_index()\n",
    "\n",
    "    return df_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df, column_groupby, column):\n",
    "\n",
    "    group_mean = df.groupby(column_groupby)[column].transform('mean')\n",
    "    overall_mean = df[column].mean()\n",
    "    df[column] = df[column].fillna(group_mean).fillna(overall_mean)\n",
    "    # df[f'{column}_{\"New\"}'] = df[column].fillna(group_mean).fillna(overall_mean)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = X_train.merge(train_series_data_stats, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_df = merged_data.select_dtypes(include='number')\n",
    "correlation_matrix = merged_data_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix.to_excel('corr_matrix.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = [col for col in merged_data_df.columns if col.startswith(\"stat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_na(X_train, 'PCIAT-PCIAT_Total', 'FGC-FGC_CU')\n",
    "df = fill_na(X_train, 'PCIAT-PCIAT_Total', 'Physical-Systolic_BP')\n",
    "df = fill_na(X_train, 'PCIAT-PCIAT_Total', 'Physical-BMI')\n",
    "df = fill_na(X_train, 'PCIAT-PCIAT_Total', 'BIA-BIA_BMC')\n",
    "df = fill_na(X_train, 'PCIAT-PCIAT_Total', 'BIA-BIA_BMI')\n",
    "df = fill_na(pd.concat([X_train, y_train], axis=1), 'sii', 'PCIAT-PCIAT_Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = stat_columns\n",
    "column_groupby = 'PCIAT-PCIAT_Total'\n",
    "column_agg=['FGC-FGC_CU','Physical-Systolic_BP','Physical-BMI','BIA-BIA_BMC','BIA-BIA_BMI','Basic_Demos-Sex']\n",
    "# column_agg=['Basic_Demos-Sex','BIA-BIA_BMC']\n",
    "# column_agg=['FGC-FGC_CU','Physical-Systolic_BP','Physical-Diastolic_BP','Physical-BMI'] # 0.152\n",
    "\n",
    "df_agg = get_aggregations(df, column_groupby=column_groupby, column_agg=column_agg)\n",
    "\n",
    "for column in df_agg.columns:\n",
    "    df_agg[column] = df_agg[column].fillna(df_agg[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# import pandas as pd\n",
    "\n",
    "# # Initialize PolynomialFeatures with specified degree\n",
    "# poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "# columns=['FGC-FGC_CU','Physical-Systolic_BP','Physical-BMI','BIA-BIA_BMC','BIA-BIA_BMI']\n",
    "# columns_new = [col + \"_New\" for col in columns]\n",
    "\n",
    "# # Select columns and generate polynomial features\n",
    "# poly_features = df[columns_new]\n",
    "# poly_array = poly.fit_transform(poly_features)\n",
    "# poly_df = pd.DataFrame(poly_array, columns=poly.get_feature_names_out(columns_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with highest correlation to PCIAT-PCIAT_Total \n",
      "\n",
      "Min_FGC-FGC_CU: 0.6346970261059559 \n",
      "\n",
      "Min_Physical-Systolic_BP: 0.5868623112249651 \n",
      "\n",
      "Median_Physical-BMI: 0.646820881538091 \n",
      "\n",
      "Min_BIA-BIA_BMC: 0.5264354125489384 \n",
      "\n",
      "Min_BIA-BIA_BMI: 0.6816141947983803 \n",
      "\n",
      "Max_Basic_Demos-Sex: 0.468028972462439 \n",
      "\n",
      "['Min_FGC-FGC_CU', 'Min_Physical-Systolic_BP', 'Median_Physical-BMI', 'Min_BIA-BIA_BMC', 'Min_BIA-BIA_BMI', 'Max_Basic_Demos-Sex']\n"
     ]
    }
   ],
   "source": [
    "print(f'Features with highest correlation to {column_groupby} \\n')\n",
    "columns_corr=[]\n",
    "for column in column_agg:\n",
    "\n",
    "    corr_df = df_agg.loc[:, df_agg.columns[df_agg.columns.str.endswith(column)].tolist()]\n",
    "    corr_df[column_groupby] = df_agg[column_groupby]\n",
    "    correlation_matrix = corr_df.corr()\n",
    "    feature_highest_corr = correlation_matrix[column_groupby].drop(column_groupby).abs().idxmax()\n",
    "    feature_corr_value = correlation_matrix[column_groupby].drop(column_groupby).abs().max()\n",
    "    print(f'{feature_highest_corr}: {feature_corr_value} \\n')\n",
    "\n",
    "    columns_corr.append(feature_highest_corr)\n",
    "\n",
    "print(columns_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corr = [item for item in columns_corr if item is not None and not (isinstance(item, float) and np.isnan(item))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_columns = other_columns + [column_groupby] + columns_corr\n",
    "all_columns = [column_groupby] + columns_corr + other_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_df_agg = [column_groupby] + columns_corr\n",
    "df_agg = df_agg.loc[:, columns_df_agg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>Min_FGC-FGC_CU</th>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <th>Min_BIA-BIA_BMC</th>\n",
       "      <th>Min_BIA-BIA_BMI</th>\n",
       "      <th>Max_Basic_Demos-Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.881874</td>\n",
       "      <td>3.409781</td>\n",
       "      <td>93.755319</td>\n",
       "      <td>20.056653</td>\n",
       "      <td>1.502083</td>\n",
       "      <td>15.610619</td>\n",
       "      <td>0.904255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.031928</td>\n",
       "      <td>6.900725</td>\n",
       "      <td>19.137132</td>\n",
       "      <td>3.899655</td>\n",
       "      <td>3.002747</td>\n",
       "      <td>4.618211</td>\n",
       "      <td>0.295818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.515430</td>\n",
       "      <td>-7.789610</td>\n",
       "      <td>0.048267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>17.880742</td>\n",
       "      <td>-0.057405</td>\n",
       "      <td>13.474475</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>19.177754</td>\n",
       "      <td>1.822565</td>\n",
       "      <td>14.221050</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>20.495010</td>\n",
       "      <td>2.923608</td>\n",
       "      <td>16.300300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>39.339185</td>\n",
       "      <td>8.168670</td>\n",
       "      <td>39.343500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PCIAT-PCIAT_Total  Min_FGC-FGC_CU  Min_Physical-Systolic_BP  \\\n",
       "count          94.000000       94.000000                 94.000000   \n",
       "mean           45.881874        3.409781                 93.755319   \n",
       "std            27.031928        6.900725                 19.137132   \n",
       "min             0.000000        0.000000                  0.000000   \n",
       "25%            23.250000        0.000000                 87.000000   \n",
       "50%            45.500000        0.000000                 93.000000   \n",
       "75%            68.750000        3.000000                101.000000   \n",
       "max            93.000000       28.000000                166.000000   \n",
       "\n",
       "       Median_Physical-BMI  Min_BIA-BIA_BMC  Min_BIA-BIA_BMI  \\\n",
       "count            94.000000        94.000000        94.000000   \n",
       "mean             20.056653         1.502083        15.610619   \n",
       "std               3.899655         3.002747         4.618211   \n",
       "min              15.515430        -7.789610         0.048267   \n",
       "25%              17.880742        -0.057405        13.474475   \n",
       "50%              19.177754         1.822565        14.221050   \n",
       "75%              20.495010         2.923608        16.300300   \n",
       "max              39.339185         8.168670        39.343500   \n",
       "\n",
       "       Max_Basic_Demos-Sex  \n",
       "count            94.000000  \n",
       "mean              0.904255  \n",
       "std               0.295818  \n",
       "min               0.000000  \n",
       "25%               1.000000  \n",
       "50%               1.000000  \n",
       "75%               1.000000  \n",
       "max               1.000000  "
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [column_groupby]\n",
    "# columns = columns + columns_corr + other_columns\n",
    "# print(columns)\n",
    "new_X_train = X_train.merge(df_agg, how='left', on=column_groupby)[all_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_agg.columns:\n",
    "    new_X_train[column] = new_X_train[column].fillna(df_agg[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in other_columns:\n",
    "    new_X_train[column] = new_X_train[column].fillna(new_X_train[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3960"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train.isna().sum()\n",
    "len(new_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = new_X_train.select_dtypes(include='number')\n",
    "correlation_matrix = new_df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>Min_FGC-FGC_CU</th>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <th>Min_BIA-BIA_BMC</th>\n",
       "      <th>Min_BIA-BIA_BMI</th>\n",
       "      <th>Max_Basic_Demos-Sex</th>\n",
       "      <th>stat_0</th>\n",
       "      <th>stat_1</th>\n",
       "      <th>stat_2</th>\n",
       "      <th>...</th>\n",
       "      <th>stat_86</th>\n",
       "      <th>stat_87</th>\n",
       "      <th>stat_88</th>\n",
       "      <th>stat_89</th>\n",
       "      <th>stat_90</th>\n",
       "      <th>stat_91</th>\n",
       "      <th>stat_92</th>\n",
       "      <th>stat_93</th>\n",
       "      <th>stat_94</th>\n",
       "      <th>stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567088</td>\n",
       "      <td>0.592919</td>\n",
       "      <td>0.760885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.593088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_FGC-FGC_CU</th>\n",
       "      <td>0.567088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638476</td>\n",
       "      <td>-0.686285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <td>0.592919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <td>0.760885</td>\n",
       "      <td>0.600485</td>\n",
       "      <td>0.527087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_BIA-BIA_BMC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat_91</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat_92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat_93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat_94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat_95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          PCIAT-PCIAT_Total  Min_FGC-FGC_CU  \\\n",
       "PCIAT-PCIAT_Total                  1.000000        0.567088   \n",
       "Min_FGC-FGC_CU                     0.567088        1.000000   \n",
       "Min_Physical-Systolic_BP           0.592919             NaN   \n",
       "Median_Physical-BMI                0.760885        0.600485   \n",
       "Min_BIA-BIA_BMC                         NaN             NaN   \n",
       "...                                     ...             ...   \n",
       "stat_91                                 NaN             NaN   \n",
       "stat_92                                 NaN             NaN   \n",
       "stat_93                                 NaN             NaN   \n",
       "stat_94                                 NaN             NaN   \n",
       "stat_95                                 NaN             NaN   \n",
       "\n",
       "                          Min_Physical-Systolic_BP  Median_Physical-BMI  \\\n",
       "PCIAT-PCIAT_Total                         0.592919             0.760885   \n",
       "Min_FGC-FGC_CU                                 NaN             0.600485   \n",
       "Min_Physical-Systolic_BP                  1.000000             0.527087   \n",
       "Median_Physical-BMI                       0.527087             1.000000   \n",
       "Min_BIA-BIA_BMC                                NaN                  NaN   \n",
       "...                                            ...                  ...   \n",
       "stat_91                                        NaN                  NaN   \n",
       "stat_92                                        NaN                  NaN   \n",
       "stat_93                                        NaN                  NaN   \n",
       "stat_94                                        NaN                  NaN   \n",
       "stat_95                                        NaN                  NaN   \n",
       "\n",
       "                          Min_BIA-BIA_BMC  Min_BIA-BIA_BMI  \\\n",
       "PCIAT-PCIAT_Total                     NaN         0.593088   \n",
       "Min_FGC-FGC_CU                        NaN         0.638476   \n",
       "Min_Physical-Systolic_BP              NaN              NaN   \n",
       "Median_Physical-BMI                   NaN         0.619717   \n",
       "Min_BIA-BIA_BMC                       1.0              NaN   \n",
       "...                                   ...              ...   \n",
       "stat_91                               NaN              NaN   \n",
       "stat_92                               NaN              NaN   \n",
       "stat_93                               NaN              NaN   \n",
       "stat_94                               NaN              NaN   \n",
       "stat_95                               NaN              NaN   \n",
       "\n",
       "                          Max_Basic_Demos-Sex  stat_0  stat_1  stat_2  ...  \\\n",
       "PCIAT-PCIAT_Total                         NaN     NaN     NaN     NaN  ...   \n",
       "Min_FGC-FGC_CU                      -0.686285     NaN     NaN     NaN  ...   \n",
       "Min_Physical-Systolic_BP                  NaN     NaN     NaN     NaN  ...   \n",
       "Median_Physical-BMI                       NaN     NaN     NaN     NaN  ...   \n",
       "Min_BIA-BIA_BMC                           NaN     NaN     NaN     NaN  ...   \n",
       "...                                       ...     ...     ...     ...  ...   \n",
       "stat_91                                   NaN     NaN     NaN     NaN  ...   \n",
       "stat_92                                   NaN     NaN     NaN     NaN  ...   \n",
       "stat_93                                   NaN     NaN     NaN     NaN  ...   \n",
       "stat_94                                   NaN     NaN     NaN     NaN  ...   \n",
       "stat_95                                   NaN     NaN     NaN     NaN  ...   \n",
       "\n",
       "                          stat_86  stat_87  stat_88  stat_89  stat_90  \\\n",
       "PCIAT-PCIAT_Total             NaN      NaN      NaN      NaN      NaN   \n",
       "Min_FGC-FGC_CU                NaN      NaN      NaN      NaN      NaN   \n",
       "Min_Physical-Systolic_BP      NaN      NaN      NaN      NaN      NaN   \n",
       "Median_Physical-BMI           NaN      NaN      NaN      NaN      NaN   \n",
       "Min_BIA-BIA_BMC               NaN      NaN      NaN      NaN      NaN   \n",
       "...                           ...      ...      ...      ...      ...   \n",
       "stat_91                       NaN      NaN      NaN      NaN      NaN   \n",
       "stat_92                       NaN      NaN      NaN      NaN      NaN   \n",
       "stat_93                       NaN      NaN      NaN      NaN      NaN   \n",
       "stat_94                       NaN      NaN      NaN      NaN      NaN   \n",
       "stat_95                       NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "                          stat_91  stat_92  stat_93  stat_94  stat_95  \n",
       "PCIAT-PCIAT_Total             NaN      NaN      NaN      NaN      NaN  \n",
       "Min_FGC-FGC_CU                NaN      NaN      NaN      NaN      NaN  \n",
       "Min_Physical-Systolic_BP      NaN      NaN      NaN      NaN      NaN  \n",
       "Median_Physical-BMI           NaN      NaN      NaN      NaN      NaN  \n",
       "Min_BIA-BIA_BMC               NaN      NaN      NaN      NaN      NaN  \n",
       "...                           ...      ...      ...      ...      ...  \n",
       "stat_91                       1.0      NaN      NaN      NaN      NaN  \n",
       "stat_92                       NaN      1.0      NaN      NaN      NaN  \n",
       "stat_93                       NaN      NaN      1.0      NaN      NaN  \n",
       "stat_94                       NaN      NaN      NaN      1.0      NaN  \n",
       "stat_95                       NaN      NaN      NaN      NaN      1.0  \n",
       "\n",
       "[103 rows x 103 columns]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix[(correlation_matrix > 0.5) | (correlation_matrix < -0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix.to_excel('corr_matrix_05.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.concat([new_X_train, y_train], axis=1)\n",
    "df = df[df['sii'].notna()]\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['sii']\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8174420052972409\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train_split, y_train_split)\n",
    "test_score = reg.score(X_test_split, y_test_split)\n",
    "print(f'Test Score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_indexes = y_train[y_train.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_null = new_X_train.iloc[null_indexes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_null) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 1224.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([0.71919516, 0.81919516, 0.91919516, 1.01919516, 1.11919516,\n",
       "        1.21919516, 1.31919516, 1.41919516, 1.51919516, 1.61919516,\n",
       "        1.71919516]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.iloc[null_indexes] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.round(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_X_train.drop(columns=column_groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_linear_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_X_train, local_X_test, local_y_train, local_y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Assume 'feature_to_scale' is the name of the feature you want to scale\n",
    "# feature_to_scale = 'Max_stat_72'\n",
    "\n",
    "# # Create an instance of StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit and transform only the selected feature\n",
    "# local_X_train[[feature_to_scale]] = scaler.fit_transform(local_X_train[[feature_to_scale]])\n",
    "# local_X_test[[feature_to_scale]] = scaler.transform(local_X_test[[feature_to_scale]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# feature_to_scale = 'Mean_Basic_Demos-Age'\n",
    "\n",
    "# # Initialize MinMaxScaler\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# # Fit and transform on the training set, and transform on the test set\n",
    "# local_X_train[[feature_to_scale]] = scaler.fit_transform(local_X_train[[feature_to_scale]])\n",
    "# local_X_test[[feature_to_scale]] = scaler.transform(local_X_test[[feature_to_scale]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# # Initialize the model\n",
    "# model = LGBMRegressor()\n",
    "\n",
    "# # Parameter grid for tuning\n",
    "# param_grid = {\n",
    "#     'num_leaves': [20, 31, 40, 50],\n",
    "#     'max_depth': [-1, 5, 10, 15],\n",
    "#     'learning_rate': [0.1, 0.05, 0.01],\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'min_child_samples': [10, 20, 30],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_distributions=param_grid,\n",
    "#     n_iter=50,  # Number of parameter combinations to try\n",
    "#     scoring='neg_mean_squared_error',  # Customize based on your task\n",
    "#     cv=5,  # Number of folds for cross-validation\n",
    "#     verbose=1,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit the randomized search\n",
    "# random_search.fit(local_X_train, local_y_train)\n",
    "\n",
    "# # Best parameters and score\n",
    "# print(\"Best parameters found: \", random_search.best_params_)\n",
    "# print(\"Best score found: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Train the final model with the best parameters\n",
    "# best_params = random_search.best_params_  # or grid_search.best_params_\n",
    "# final_model = LGBMRegressor(**best_params)\n",
    "# final_model.fit(local_X_train, local_y_train)\n",
    "\n",
    "# # Predict and evaluate on the test set\n",
    "# local_y_pred = final_model.predict(local_X_test)\n",
    "# mse = mean_squared_error(local_y_test, local_y_pred)\n",
    "# r2 = r2_score(local_y_test, local_y_pred)\n",
    "# print(\"Mean Squared Error on Test Set:\", mse)\n",
    "# print(\"R² Score on Test Set:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LinearRegression()\n",
    "final_model.fit(local_X_train, local_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5464877730251877"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(local_X_test, local_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_y_pred = final_model.predict(local_X_test)\n",
    "local_y_train_pred = final_model.predict(local_X_train)\n",
    "\n",
    "# conditions = [local_y_pred <= 0, local_y_pred <= 1, local_y_pred <= 2, local_y_pred <= 3]\n",
    "# choices = [0, 1, 2, 3]\n",
    "# local_y_pred = np.select(conditions, choices, default=1)\n",
    "\n",
    "local_y_pred = np.round(local_y_pred).astype(int)\n",
    "local_y_train_pred = np.round(local_y_train_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "final_model = RandomForestClassifier(class_weight={0: 1, 1: 1, 2: 1, 3: 3})  # Give higher weight to class 3\n",
    "final_model.fit(local_X_train, local_y_train)\n",
    "\n",
    "final_model.score(local_X_test, local_y_test)\n",
    "local_y_pred = final_model.predict(local_X_test)\n",
    "local_y_train_pred = final_model.predict(local_X_train)\n",
    "local_y_pred = np.round(local_y_pred).astype(int)\n",
    "local_y_train_pred = np.round(local_y_train_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# final_model = xgb.XGBClassifier(scale_pos_weight=10)  # Adjust 'scale_pos_weight' for class '3'\n",
    "# final_model.fit(local_X_train, local_y_train)\n",
    "\n",
    "# final_model.score(local_X_test, local_y_test)\n",
    "# local_y_pred = final_model.predict(local_X_test)\n",
    "# local_y_train_pred = final_model.predict(local_X_train)\n",
    "# local_y_pred = np.round(local_y_pred).astype(int)\n",
    "# local_y_train_pred = np.round(local_y_train_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# final_model = xgb.XGBClassifier(\n",
    "#     learning_rate=0.05,\n",
    "#     n_estimators=150,\n",
    "#     subsample=0.8,  # Randomly sample 80% of training data\n",
    "#     colsample_bytree=0.8,  # Randomly sample 80% of features\n",
    "#     max_depth=6,  # Limiting the depth of trees\n",
    "#     reg_alpha=1,  # L1 regularization\n",
    "#     reg_lambda=1  # L2 regularization\n",
    "# )\n",
    "# final_model.fit(local_X_train, local_y_train)\n",
    "\n",
    "# final_model.score(local_X_test, local_y_test)\n",
    "# local_y_pred = final_model.predict(local_X_test)\n",
    "# local_y_train_pred = final_model.predict(local_X_train)\n",
    "# local_y_pred = np.round(local_y_pred).astype(int)\n",
    "# local_y_train_pred = np.round(local_y_train_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'max_depth': [10, 12, 15],\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'min_data_in_leaf': [10, 13, 20],\n",
    "#     'feature_fraction': [0.8, 0.9, 1.0],\n",
    "#     'bagging_fraction': [0.7, 0.8, 0.9],\n",
    "#     'bagging_freq': [2, 4, 5],\n",
    "#     'lambda_l1': [1, 5, 10],\n",
    "#     'lambda_l2': [0.01, 0.1, 1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=final_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18219\n",
      "[LightGBM] [Info] Number of data points in the train set: 3168, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.706755\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "final_model = lgb.LGBMRegressor(**{\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 150,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  # Increased from 6.59\n",
    "    'lambda_l2': 0.01  # Increased from 2.68e-06\n",
    "})\n",
    "\n",
    "final_model.fit(local_X_train, local_y_train)\n",
    "\n",
    "final_model.score(local_X_test, local_y_test)\n",
    "local_y_pred = final_model.predict(local_X_test)\n",
    "local_y_train_pred = final_model.predict(local_X_train)\n",
    "local_y_pred = np.round(local_y_pred).astype(int)\n",
    "local_y_train_pred = np.round(local_y_train_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18026\n",
      "[LightGBM] [Info] Number of data points in the train set: 2534, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.698500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18043\n",
      "[LightGBM] [Info] Number of data points in the train set: 2534, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.712313\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18003\n",
      "[LightGBM] [Info] Number of data points in the train set: 2534, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.710339\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18047\n",
      "[LightGBM] [Info] Number of data points in the train set: 2535, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.697436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18047\n",
      "[LightGBM] [Info] Number of data points in the train set: 2535, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.715187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9474074039087848)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(final_model, local_X_train, local_y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train QWK Score: 0.9799664655646693\n",
      "Validation QWK Score: 0.9685757039858522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "qwk_score_train = cohen_kappa_score(local_y_train, local_y_train_pred, weights='quadratic')\n",
    "qwk_score_val = cohen_kappa_score(local_y_test, local_y_pred, weights='quadratic')\n",
    "print(\"Train QWK Score:\", qwk_score_train)\n",
    "print(\"Validation QWK Score:\", qwk_score_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([local_y_test.reset_index(), pd.DataFrame(local_y_pred)], axis=1)\n",
    "results.to_excel('results_local_test_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suponha que você tenha um DataFrame `train` e `test`, e a coluna `target` contém a variável alvo\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Treino\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='sii', data=pd.DataFrame(local_y_train))\n",
    "plt.title('Distribuição das Classes - Treino')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "# Teste\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='sii', data=pd.DataFrame(local_y_test))\n",
    "plt.title('Distribuição das Classes - Teste')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in columns_corr:\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     # Treino\n",
    "#     sns.kdeplot(local_X_train[column], label='Treino', color='blue')\n",
    "#     sns.kdeplot(local_X_test[column], label='Teste', color='red')\n",
    "#     plt.title(f'Distribuição {column} - Treino vs Teste')\n",
    "#     plt.xlabel('Valores da Feature')\n",
    "#     plt.ylabel('Densidade')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PCIAT-PCIAT_Total',\n",
       " 'Min_FGC-FGC_CU',\n",
       " 'Min_Physical-Systolic_BP',\n",
       " 'Median_Physical-BMI',\n",
       " 'Min_BIA-BIA_BMC',\n",
       " 'Min_BIA-BIA_BMI',\n",
       " 'Max_Basic_Demos-Sex',\n",
       " 'stat_0',\n",
       " 'stat_1',\n",
       " 'stat_2',\n",
       " 'stat_3',\n",
       " 'stat_4',\n",
       " 'stat_5',\n",
       " 'stat_6',\n",
       " 'stat_7',\n",
       " 'stat_8',\n",
       " 'stat_9',\n",
       " 'stat_10',\n",
       " 'stat_11',\n",
       " 'stat_12',\n",
       " 'stat_13',\n",
       " 'stat_14',\n",
       " 'stat_15',\n",
       " 'stat_16',\n",
       " 'stat_17',\n",
       " 'stat_18',\n",
       " 'stat_19',\n",
       " 'stat_20',\n",
       " 'stat_21',\n",
       " 'stat_22',\n",
       " 'stat_23',\n",
       " 'stat_24',\n",
       " 'stat_25',\n",
       " 'stat_26',\n",
       " 'stat_27',\n",
       " 'stat_28',\n",
       " 'stat_29',\n",
       " 'stat_30',\n",
       " 'stat_31',\n",
       " 'stat_32',\n",
       " 'stat_33',\n",
       " 'stat_34',\n",
       " 'stat_35',\n",
       " 'stat_36',\n",
       " 'stat_37',\n",
       " 'stat_38',\n",
       " 'stat_39',\n",
       " 'stat_40',\n",
       " 'stat_41',\n",
       " 'stat_42',\n",
       " 'stat_43',\n",
       " 'stat_44',\n",
       " 'stat_45',\n",
       " 'stat_46',\n",
       " 'stat_47',\n",
       " 'stat_48',\n",
       " 'stat_49',\n",
       " 'stat_50',\n",
       " 'stat_51',\n",
       " 'stat_52',\n",
       " 'stat_53',\n",
       " 'stat_54',\n",
       " 'stat_55',\n",
       " 'stat_56',\n",
       " 'stat_57',\n",
       " 'stat_58',\n",
       " 'stat_59',\n",
       " 'stat_60',\n",
       " 'stat_61',\n",
       " 'stat_62',\n",
       " 'stat_63',\n",
       " 'stat_64',\n",
       " 'stat_65',\n",
       " 'stat_66',\n",
       " 'stat_67',\n",
       " 'stat_68',\n",
       " 'stat_69',\n",
       " 'stat_70',\n",
       " 'stat_71',\n",
       " 'stat_72',\n",
       " 'stat_73',\n",
       " 'stat_74',\n",
       " 'stat_75',\n",
       " 'stat_76',\n",
       " 'stat_77',\n",
       " 'stat_78',\n",
       " 'stat_79',\n",
       " 'stat_80',\n",
       " 'stat_81',\n",
       " 'stat_82',\n",
       " 'stat_83',\n",
       " 'stat_84',\n",
       " 'stat_85',\n",
       " 'stat_86',\n",
       " 'stat_87',\n",
       " 'stat_88',\n",
       " 'stat_89',\n",
       " 'stat_90',\n",
       " 'stat_91',\n",
       " 'stat_92',\n",
       " 'stat_93',\n",
       " 'stat_94',\n",
       " 'stat_95']"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FGC-FGC_CU',\n",
       " 'Physical-Systolic_BP',\n",
       " 'Physical-BMI',\n",
       " 'BIA-BIA_BMC',\n",
       " 'BIA-BIA_BMI',\n",
       " 'Basic_Demos-Sex']"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_agg\n",
    "# print(columns_agg_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_X_test = X_test.merge(test_series_data_stats, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in other_columns:\n",
    "    merged_data_X_test[column] = merged_data_X_test[column].fillna(new_X_train[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = merged_data_X_test.loc[:, column_agg + other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-638-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-638-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-638-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-638-4db0297c3fc1>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column]\n"
     ]
    }
   ],
   "source": [
    "for column in column_agg:\n",
    "    index = column_agg.index(column)\n",
    "    if X_test_predict[column].isna().sum() > 0:\n",
    "        try:\n",
    "            X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
    "        except:\n",
    "            print(index)\n",
    "    else:\n",
    "        X_test_predict[columns_corr[index]] = X_test_predict[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = X_test_predict.loc[:, columns_corr + other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.893\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.784\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    }
   ],
   "source": [
    "y_test = final_model.predict(X_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37503572, 0.3678674 , 1.51616121, 2.04539852, 0.99413267,\n",
       "       2.37452392, 2.0577014 , 1.79846387, 0.99413267, 0.99413267,\n",
       "       0.99413267, 0.99413267, 2.35805826, 1.52523812, 0.99413267,\n",
       "       2.11392724, 1.5725672 , 0.75204031, 2.21000393, 0.99413267])"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_round = np.round(y_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_round = round_final_results(y_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 2 1 2 2 2 1 1 1 1 2 2 1 2 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame({'id': X_test['id'], 'sii': y_test_round})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df_y_test.to_csv(f'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    1\n",
       "1   000fd460    0\n",
       "2   00105258    2\n",
       "3   00115b9f    2\n",
       "4   0016bb22    1\n",
       "5   001f3379    2\n",
       "6   0038ba98    2\n",
       "7   0068a485    2\n",
       "8   0069fbed    1\n",
       "9   0083e397    1\n",
       "10  0087dd65    1\n",
       "11  00abe655    1\n",
       "12  00ae59c9    2\n",
       "13  00af6387    2\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    2\n",
       "16  00d56d4b    2\n",
       "17  00d9913d    1\n",
       "18  00e6167c    2\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([X_train,y_train], axis=1).to_csv('df_final_to_powerbi_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
