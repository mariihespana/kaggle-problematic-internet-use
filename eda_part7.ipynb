{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df=pd.read_csv(\"df_final_2.csv\")\n",
    "X_train = pd.read_csv('child-mind-institute-problematic-internet-use/train.csv').iloc[:, :-1]\n",
    "y_train = pd.read_csv('child-mind-institute-problematic-internet-use/train.csv').iloc[:, -1]\n",
    "X_test = pd.read_csv('child-mind-institute-problematic-internet-use/test.csv').iloc[:, :-1]\n",
    "y_test = pd.read_csv('child-mind-institute-problematic-internet-use/test.csv').iloc[:, -1]\n",
    "\n",
    "# X_train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv').iloc[:, :-1]\n",
    "# y_train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv').iloc[:, -1]\n",
    "# X_test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv').iloc[:, :-1]\n",
    "# y_test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv').iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series_data_stats = pd.read_csv('train_series_data_stats.csv')\n",
    "test_series_data_stats = pd.read_csv('test_series_data_stats.csv')\n",
    "\n",
    "# train_series_data_stats = pd.read_csv('/kaggle/input/train_series_data_stats.csv')\n",
    "# test_series_data_stats = pd.read_csv('/kaggle/input/test_series_data_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "def get_aggregations(df, column_groupby, column_agg):\n",
    "\n",
    "    if not isinstance(column_agg, list):\n",
    "        column_agg = [column_agg]\n",
    "    \n",
    "    # Create the aggregation dictionary\n",
    "    aggregation_dict = {}\n",
    "    for col in column_agg:\n",
    "        aggregation_dict.update({\n",
    "            f'Median_{col}': (col, 'median'),\n",
    "            f'Max_{col}': (col, 'max'),\n",
    "            f'Min_{col}': (col, 'min'),\n",
    "            f'Sum_{col}': (col, 'sum'),\n",
    "            f'Std_{col}': (col, 'std'),\n",
    "            f'Mean_{col}': (col, 'mean')\n",
    "        })\n",
    "    \n",
    "    # Perform groupby and aggregation\n",
    "    df_agg = df.groupby(column_groupby).agg(**aggregation_dict).reset_index()\n",
    "\n",
    "    return df_agg\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def round_final_results(y_pred):\n",
    "    conditions = [y_test <= 0.5, y_test <= 1.5, y_test <= 2.5, y_test > 2.5]\n",
    "    choices = [0, 1, 2, 3]\n",
    "    y_pred_round = np.select(conditions, choices, default=1)\n",
    "    return y_pred_round\n",
    "\n",
    "def evaluate_linear_models(X, y, models=None, test_size=0.3, random_state=42):\n",
    "    # Default models if none are specified\n",
    "    if models is None:\n",
    "        models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'Ridge': Ridge(),\n",
    "            'Lasso': Lasso(),\n",
    "            'ElasticNet': ElasticNet()\n",
    "        }\n",
    "\n",
    "    # Split the data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize dictionary to store QWK scores for each model\n",
    "    results = {}\n",
    "\n",
    "    # Iterate over each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Round predictions to nearest integers if the target variable is categorical\n",
    "        y_train_pred_rounded = np.round(y_train_pred).astype(int)\n",
    "        y_val_pred_rounded = np.round(y_val_pred).astype(int)\n",
    "        \n",
    "        # Calculate QWK scores\n",
    "        qwk_score_train = cohen_kappa_score(y_train, y_train_pred_rounded, weights='quadratic')\n",
    "        qwk_score_val = cohen_kappa_score(y_val, y_val_pred_rounded, weights='quadratic')\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            \"Train QWK Score\": qwk_score_train,\n",
    "            \"Validation QWK Score\": qwk_score_val\n",
    "        }\n",
    "\n",
    "        # Print results for each model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Train QWK Score: {qwk_score_train}\")\n",
    "        print(f\"Validation QWK Score: {qwk_score_val}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_tree_models(X, y, models=None, test_size=0.3, random_state=42):\n",
    "    # Default models if none are specified\n",
    "    if models is None:\n",
    "        models = {\n",
    "            'DecisionTree': DecisionTreeRegressor(random_state=random_state),\n",
    "            'RandomForest': RandomForestRegressor(random_state=random_state),\n",
    "            'GradientBoosting': GradientBoostingRegressor(random_state=random_state),\n",
    "            'XGBoost': XGBRegressor(random_state=random_state)\n",
    "        }\n",
    "\n",
    "    # Split the data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize dictionary to store QWK scores for each model\n",
    "    results = {}\n",
    "\n",
    "    # Iterate over each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Round predictions to nearest integers since the target is categorical\n",
    "        y_train_pred_rounded = np.round(y_train_pred).astype(int)\n",
    "        y_val_pred_rounded = np.round(y_val_pred).astype(int)\n",
    "        \n",
    "        # Calculate QWK scores\n",
    "        qwk_score_train = cohen_kappa_score(y_train, y_train_pred_rounded, weights='quadratic')\n",
    "        qwk_score_val = cohen_kappa_score(y_val, y_val_pred_rounded, weights='quadratic')\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            \"Train QWK Score\": qwk_score_train,\n",
    "            \"Validation QWK Score\": qwk_score_val\n",
    "        }\n",
    "\n",
    "        # Print results for each model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Train QWK Score: {qwk_score_train}\")\n",
    "        print(f\"Validation QWK Score: {qwk_score_val}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Usage example\n",
    "# X and y should be your features and target variable DataFrames/Series\n",
    "# results = evaluate_tree_models(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = X_train.merge(train_series_data_stats, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_df = merged_data.select_dtypes(include='number')\n",
    "correlation_matrix = merged_data_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix.to_excel('corr_matrix.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = [col for col in merged_data_df.columns if col.startswith(\"stat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = []\n",
    "column_groupby = 'PCIAT-PCIAT_Total'\n",
    "column_agg=['FGC-FGC_CU','Physical-Systolic_BP','Physical-Diastolic_BP','Physical-BMI','BIA-BIA_BMC','BIA-BIA_BMI','Basic_Demos-Age','Basic_Demos-Sex'] + stat_columns\n",
    "# column_agg=['FGC-FGC_CU','Physical-Systolic_BP','Physical-Diastolic_BP','Physical-BMI'] # 0.152\n",
    "\n",
    "df_agg = get_aggregations(X_train, column_groupby=column_groupby, column_agg=column_agg)\n",
    "\n",
    "for column in df_agg.columns:\n",
    "    df_agg[column] = df_agg[column].fillna(df_agg[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # Verificar pra calcular separadamente ou tudo junto polinomios e relacoes se adicionar mais de uma coluna\n",
    "# poly_df = get_polynomial_features(df_agg, columns=column_agg, degree=2)\n",
    "\n",
    "# df_agg = pd.concat([df_agg, poly_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with highest correlation to PCIAT-PCIAT_Total \n",
      "\n",
      "Median_FGC-FGC_CU: 0.6644843180692392 \n",
      "\n",
      "Min_Physical-Systolic_BP: 0.6429503351979634 \n",
      "\n",
      "Min_Physical-Diastolic_BP: 0.6151229554265928 \n",
      "\n",
      "Median_Physical-BMI: 0.65414920713236 \n",
      "\n",
      "Median_BIA-BIA_BMC: 0.673042684902567 \n",
      "\n",
      "Min_BIA-BIA_BMI: 0.6592806566970287 \n",
      "\n",
      "Mean_Basic_Demos-Age: 0.910153146014278 \n",
      "\n",
      "Sum_Basic_Demos-Sex: 0.6056946649630189 \n",
      "\n",
      "Sum_stat_0: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_1: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_2: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_3: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_4: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_5: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_6: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_7: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_8: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_9: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_10: 0.5551210715597527 \n",
      "\n",
      "Sum_stat_11: 0.5551210715597527 \n",
      "\n",
      "Max_stat_12: 0.5846451520385825 \n",
      "\n",
      "Min_stat_13: 0.35911809334244493 \n",
      "\n",
      "Sum_stat_14: 0.5434079455039965 \n",
      "\n",
      "Max_stat_15: 0.5856244176914472 \n",
      "\n",
      "Sum_stat_16: 0.5402081876500501 \n",
      "\n",
      "Sum_stat_17: 0.478019697883667 \n",
      "\n",
      "Sum_stat_18: 0.5599401495669291 \n",
      "\n",
      "Sum_stat_19: 0.5487943577050026 \n",
      "\n",
      "Sum_stat_20: 0.5493824365346252 \n",
      "\n",
      "Sum_stat_21: 0.5475798173775323 \n",
      "\n",
      "Sum_stat_22: 0.5399527963159142 \n",
      "\n",
      "Max_stat_23: 0.5556984220838991 \n",
      "\n",
      "Max_stat_24: 0.558989243080711 \n",
      "\n",
      "Sum_stat_25: 0.5399331192016611 \n",
      "\n",
      "Sum_stat_26: 0.544953757636127 \n",
      "\n",
      "Max_stat_27: 0.5517098324181502 \n",
      "\n",
      "Sum_stat_28: 0.544460043844984 \n",
      "\n",
      "Sum_stat_29: 0.5210304151322496 \n",
      "\n",
      "Sum_stat_30: 0.5598501276387263 \n",
      "\n",
      "Sum_stat_31: 0.5519729580462597 \n",
      "\n",
      "Sum_stat_32: 0.5520782798243784 \n",
      "\n",
      "Sum_stat_33: 0.5487314939016854 \n",
      "\n",
      "Sum_stat_34: 0.5313171961131704 \n",
      "\n",
      "Sum_stat_35: 0.5440899220371899 \n",
      "\n",
      "Sum_stat_36: 0.568530925409245 \n",
      "\n",
      "Min_stat_37: 0.5816120910906462 \n",
      "\n",
      "Sum_stat_38: 0.5508092150989852 \n",
      "\n",
      "Mean_stat_39: 0.044773102729299054 \n",
      "\n",
      "Sum_stat_40: 0.5492197275594688 \n",
      "\n",
      "nan: nan \n",
      "\n",
      "nan: nan \n",
      "\n",
      "Sum_stat_43: 0.5485423202465486 \n",
      "\n",
      "Sum_stat_44: 0.2578456631522012 \n",
      "\n",
      "Sum_stat_45: 0.5471235976464343 \n",
      "\n",
      "Sum_stat_46: 0.532434731680563 \n",
      "\n",
      "Max_stat_47: 0.5528520016080029 \n",
      "\n",
      "Sum_stat_48: 0.5483045077017383 \n",
      "\n",
      "Sum_stat_49: 0.5291947687019244 \n",
      "\n",
      "Sum_stat_50: 0.5564528009721378 \n",
      "\n",
      "Sum_stat_51: 0.5020762198941637 \n",
      "\n",
      "Sum_stat_52: 0.5541930471718669 \n",
      "\n",
      "Sum_stat_53: 0.36601378152404135 \n",
      "\n",
      "Sum_stat_54: 0.4750076817339524 \n",
      "\n",
      "Sum_stat_55: 0.5488292725365528 \n",
      "\n",
      "Sum_stat_56: 0.5460524234422908 \n",
      "\n",
      "Sum_stat_57: 0.5498758720227774 \n",
      "\n",
      "Sum_stat_58: 0.5392411190452543 \n",
      "\n",
      "Max_stat_59: 0.5560815480263347 \n",
      "\n",
      "Max_stat_60: 0.6147145565169719 \n",
      "\n",
      "Min_stat_61: 0.2717652610307988 \n",
      "\n",
      "Sum_stat_62: 0.5170971044569239 \n",
      "\n",
      "Max_stat_63: 0.5843540727736966 \n",
      "\n",
      "Sum_stat_64: 0.5010843501310472 \n",
      "\n",
      "Sum_stat_65: 0.4422952011965457 \n",
      "\n",
      "Sum_stat_66: 0.5448610781989336 \n",
      "\n",
      "Sum_stat_67: 0.5485076809693799 \n",
      "\n",
      "Sum_stat_68: 0.5499136306806772 \n",
      "\n",
      "Sum_stat_69: 0.5471575942023916 \n",
      "\n",
      "Sum_stat_70: 0.5348873292292473 \n",
      "\n",
      "Max_stat_71: 0.5553381673904211 \n",
      "\n",
      "Max_stat_72: 0.6468901380953064 \n",
      "\n",
      "Sum_stat_73: 0.5120787736652717 \n",
      "\n",
      "Sum_stat_74: 0.4767786401881012 \n",
      "\n",
      "Max_stat_75: 0.5687214489430072 \n",
      "\n",
      "Sum_stat_76: 0.46145292205830213 \n",
      "\n",
      "Sum_stat_77: 0.45608090439183113 \n",
      "\n",
      "Sum_stat_78: 0.5601854943311373 \n",
      "\n",
      "Sum_stat_79: 0.5489051093854717 \n",
      "\n",
      "Sum_stat_80: 0.5503496537310353 \n",
      "\n",
      "Sum_stat_81: 0.5527939667989066 \n",
      "\n",
      "Sum_stat_82: 0.5434176120955673 \n",
      "\n",
      "Max_stat_83: 0.5558651860565047 \n",
      "\n",
      "Sum_stat_84: 0.5247436343040607 \n",
      "\n",
      "Sum_stat_85: 0.5477034112571513 \n",
      "\n",
      "Sum_stat_86: 0.5319900819781219 \n",
      "\n",
      "Sum_stat_87: 0.5409375628524036 \n",
      "\n",
      "Sum_stat_88: 0.5481289025522706 \n",
      "\n",
      "Sum_stat_89: 0.5495231865602255 \n",
      "\n",
      "Sum_stat_90: 0.5534477810480098 \n",
      "\n",
      "Sum_stat_91: 0.5495857264468315 \n",
      "\n",
      "Sum_stat_92: 0.5495513834536316 \n",
      "\n",
      "Sum_stat_93: 0.5494365229753567 \n",
      "\n",
      "Sum_stat_94: 0.544585178653966 \n",
      "\n",
      "Max_stat_95: 0.5533480195287298 \n",
      "\n",
      "['Median_FGC-FGC_CU', 'Min_Physical-Systolic_BP', 'Min_Physical-Diastolic_BP', 'Median_Physical-BMI', 'Median_BIA-BIA_BMC', 'Min_BIA-BIA_BMI', 'Mean_Basic_Demos-Age', 'Sum_Basic_Demos-Sex', 'Sum_stat_0', 'Sum_stat_1', 'Sum_stat_2', 'Sum_stat_3', 'Sum_stat_4', 'Sum_stat_5', 'Sum_stat_6', 'Sum_stat_7', 'Sum_stat_8', 'Sum_stat_9', 'Sum_stat_10', 'Sum_stat_11', 'Max_stat_12', 'Min_stat_13', 'Sum_stat_14', 'Max_stat_15', 'Sum_stat_16', 'Sum_stat_17', 'Sum_stat_18', 'Sum_stat_19', 'Sum_stat_20', 'Sum_stat_21', 'Sum_stat_22', 'Max_stat_23', 'Max_stat_24', 'Sum_stat_25', 'Sum_stat_26', 'Max_stat_27', 'Sum_stat_28', 'Sum_stat_29', 'Sum_stat_30', 'Sum_stat_31', 'Sum_stat_32', 'Sum_stat_33', 'Sum_stat_34', 'Sum_stat_35', 'Sum_stat_36', 'Min_stat_37', 'Sum_stat_38', 'Mean_stat_39', 'Sum_stat_40', nan, nan, 'Sum_stat_43', 'Sum_stat_44', 'Sum_stat_45', 'Sum_stat_46', 'Max_stat_47', 'Sum_stat_48', 'Sum_stat_49', 'Sum_stat_50', 'Sum_stat_51', 'Sum_stat_52', 'Sum_stat_53', 'Sum_stat_54', 'Sum_stat_55', 'Sum_stat_56', 'Sum_stat_57', 'Sum_stat_58', 'Max_stat_59', 'Max_stat_60', 'Min_stat_61', 'Sum_stat_62', 'Max_stat_63', 'Sum_stat_64', 'Sum_stat_65', 'Sum_stat_66', 'Sum_stat_67', 'Sum_stat_68', 'Sum_stat_69', 'Sum_stat_70', 'Max_stat_71', 'Max_stat_72', 'Sum_stat_73', 'Sum_stat_74', 'Max_stat_75', 'Sum_stat_76', 'Sum_stat_77', 'Sum_stat_78', 'Sum_stat_79', 'Sum_stat_80', 'Sum_stat_81', 'Sum_stat_82', 'Max_stat_83', 'Sum_stat_84', 'Sum_stat_85', 'Sum_stat_86', 'Sum_stat_87', 'Sum_stat_88', 'Sum_stat_89', 'Sum_stat_90', 'Sum_stat_91', 'Sum_stat_92', 'Sum_stat_93', 'Sum_stat_94', 'Max_stat_95']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-af4577e6ae9b>:8: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  feature_highest_corr = correlation_matrix[column_groupby].drop(column_groupby).abs().idxmax()\n",
      "<ipython-input-11-af4577e6ae9b>:8: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  feature_highest_corr = correlation_matrix[column_groupby].drop(column_groupby).abs().idxmax()\n"
     ]
    }
   ],
   "source": [
    "print(f'Features with highest correlation to {column_groupby} \\n')\n",
    "columns_corr=[]\n",
    "for column in column_agg:\n",
    "\n",
    "    corr_df = df_agg.loc[:, df_agg.columns[df_agg.columns.str.endswith(column)].tolist()]\n",
    "    corr_df[column_groupby] = df_agg[column_groupby]\n",
    "    correlation_matrix = corr_df.corr()\n",
    "    feature_highest_corr = correlation_matrix[column_groupby].drop(column_groupby).abs().idxmax()\n",
    "    feature_corr_value = correlation_matrix[column_groupby].drop(column_groupby).abs().max()\n",
    "    print(f'{feature_highest_corr}: {feature_corr_value} \\n')\n",
    "\n",
    "    columns_corr.append(feature_highest_corr)\n",
    "\n",
    "print(columns_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corr = [item for item in columns_corr if item is not None and not (isinstance(item, float) and np.isnan(item))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_columns = other_columns + [column_groupby] + columns_corr\n",
    "all_columns = [column_groupby] + columns_corr + other_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_df_agg = [column_groupby] + columns_corr \n",
    "df_agg = df_agg.loc[:, columns_df_agg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>Median_FGC-FGC_CU</th>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <th>Min_Physical-Diastolic_BP</th>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <th>Median_BIA-BIA_BMC</th>\n",
       "      <th>Min_BIA-BIA_BMI</th>\n",
       "      <th>Mean_Basic_Demos-Age</th>\n",
       "      <th>Sum_Basic_Demos-Sex</th>\n",
       "      <th>Sum_stat_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum_stat_86</th>\n",
       "      <th>Sum_stat_87</th>\n",
       "      <th>Sum_stat_88</th>\n",
       "      <th>Sum_stat_89</th>\n",
       "      <th>Sum_stat_90</th>\n",
       "      <th>Sum_stat_91</th>\n",
       "      <th>Sum_stat_92</th>\n",
       "      <th>Sum_stat_93</th>\n",
       "      <th>Sum_stat_94</th>\n",
       "      <th>Max_stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.075269</td>\n",
       "      <td>12.445055</td>\n",
       "      <td>94.763441</td>\n",
       "      <td>50.559140</td>\n",
       "      <td>19.788974</td>\n",
       "      <td>4.494338</td>\n",
       "      <td>15.568655</td>\n",
       "      <td>11.476051</td>\n",
       "      <td>10.720430</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>20.087548</td>\n",
       "      <td>39.349031</td>\n",
       "      <td>951.964441</td>\n",
       "      <td>6.967742</td>\n",
       "      <td>25014.088152</td>\n",
       "      <td>44767.760758</td>\n",
       "      <td>9.241359e+14</td>\n",
       "      <td>74.258065</td>\n",
       "      <td>28.010753</td>\n",
       "      <td>228.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.112983</td>\n",
       "      <td>6.410102</td>\n",
       "      <td>16.542040</td>\n",
       "      <td>10.927093</td>\n",
       "      <td>4.013770</td>\n",
       "      <td>1.103305</td>\n",
       "      <td>4.593786</td>\n",
       "      <td>1.988782</td>\n",
       "      <td>13.655995</td>\n",
       "      <td>4.156603e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>27.172797</td>\n",
       "      <td>52.922134</td>\n",
       "      <td>1190.831888</td>\n",
       "      <td>8.099184</td>\n",
       "      <td>31913.658003</td>\n",
       "      <td>55883.147804</td>\n",
       "      <td>1.153436e+15</td>\n",
       "      <td>92.755746</td>\n",
       "      <td>36.182056</td>\n",
       "      <td>147.779712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.515430</td>\n",
       "      <td>2.794585</td>\n",
       "      <td>0.048267</td>\n",
       "      <td>7.678571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.570840</td>\n",
       "      <td>3.651295</td>\n",
       "      <td>13.487900</td>\n",
       "      <td>10.034483</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.792560e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.214520</td>\n",
       "      <td>10.452697</td>\n",
       "      <td>267.958488</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5457.549988</td>\n",
       "      <td>12456.000000</td>\n",
       "      <td>2.591850e+14</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.618419</td>\n",
       "      <td>4.342710</td>\n",
       "      <td>14.225500</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.846621e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.676479</td>\n",
       "      <td>30.762908</td>\n",
       "      <td>803.509445</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18945.199951</td>\n",
       "      <td>37570.333496</td>\n",
       "      <td>7.769350e+14</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>228.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>19.933707</td>\n",
       "      <td>4.914095</td>\n",
       "      <td>16.238800</td>\n",
       "      <td>12.769231</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.655966e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>29.146603</td>\n",
       "      <td>56.460919</td>\n",
       "      <td>1387.328873</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>34997.166748</td>\n",
       "      <td>66547.166504</td>\n",
       "      <td>1.375780e+15</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.339185</td>\n",
       "      <td>8.182705</td>\n",
       "      <td>39.343500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>3.579265e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>240.069235</td>\n",
       "      <td>468.019582</td>\n",
       "      <td>10430.769112</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>276951.082718</td>\n",
       "      <td>488469.416504</td>\n",
       "      <td>1.008740e+16</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PCIAT-PCIAT_Total  Median_FGC-FGC_CU  Min_Physical-Systolic_BP  \\\n",
       "count          93.000000          93.000000                 93.000000   \n",
       "mean           46.075269          12.445055                 94.763441   \n",
       "std            27.112983           6.410102                 16.542040   \n",
       "min             0.000000           3.000000                 49.000000   \n",
       "25%            23.000000           8.000000                 87.000000   \n",
       "50%            46.000000          11.000000                 93.000000   \n",
       "75%            69.000000          14.000000                101.000000   \n",
       "max            93.000000          35.000000                166.000000   \n",
       "\n",
       "       Min_Physical-Diastolic_BP  Median_Physical-BMI  Median_BIA-BIA_BMC  \\\n",
       "count                  93.000000            93.000000           93.000000   \n",
       "mean                   50.559140            19.788974            4.494338   \n",
       "std                    10.927093             4.013770            1.103305   \n",
       "min                    11.000000            15.515430            2.794585   \n",
       "25%                    45.000000            17.570840            3.651295   \n",
       "50%                    50.000000            18.618419            4.342710   \n",
       "75%                    56.000000            19.933707            4.914095   \n",
       "max                    87.000000            39.339185            8.182705   \n",
       "\n",
       "       Min_BIA-BIA_BMI  Mean_Basic_Demos-Age  Sum_Basic_Demos-Sex  \\\n",
       "count        93.000000             93.000000            93.000000   \n",
       "mean         15.568655             11.476051            10.720430   \n",
       "std           4.593786              1.988782            13.655995   \n",
       "min           0.048267              7.678571             0.000000   \n",
       "25%          13.487900             10.034483             3.000000   \n",
       "50%          14.225500             11.384615             9.000000   \n",
       "75%          16.238800             12.769231            16.000000   \n",
       "max          39.343500             17.000000           116.000000   \n",
       "\n",
       "         Sum_stat_0  ...  Sum_stat_86  Sum_stat_87   Sum_stat_88  Sum_stat_89  \\\n",
       "count  9.300000e+01  ...    93.000000    93.000000     93.000000    93.000000   \n",
       "mean   3.382464e+06  ...    20.087548    39.349031    951.964441     6.967742   \n",
       "std    4.156603e+06  ...    27.172797    52.922134   1190.831888     8.099184   \n",
       "min    0.000000e+00  ...     0.000000     0.000000      0.000000     0.000000   \n",
       "25%    7.792560e+05  ...     5.214520    10.452697    267.958488     2.000000   \n",
       "50%    2.846621e+06  ...    14.676479    30.762908    803.509445     6.000000   \n",
       "75%    4.655966e+06  ...    29.146603    56.460919   1387.328873     9.000000   \n",
       "max    3.579265e+07  ...   240.069235   468.019582  10430.769112    68.000000   \n",
       "\n",
       "         Sum_stat_90    Sum_stat_91   Sum_stat_92  Sum_stat_93  Sum_stat_94  \\\n",
       "count      93.000000      93.000000  9.300000e+01    93.000000    93.000000   \n",
       "mean    25014.088152   44767.760758  9.241359e+14    74.258065    28.010753   \n",
       "std     31913.658003   55883.147804  1.153436e+15    92.755746    36.182056   \n",
       "min         0.000000       0.000000  0.000000e+00     0.000000     0.000000   \n",
       "25%      5457.549988   12456.000000  2.591850e+14    21.000000     7.000000   \n",
       "50%     18945.199951   37570.333496  7.769350e+14    63.000000    24.000000   \n",
       "75%     34997.166748   66547.166504  1.375780e+15   107.000000    40.000000   \n",
       "max    276951.082718  488469.416504  1.008740e+16   811.000000   316.000000   \n",
       "\n",
       "       Max_stat_95  \n",
       "count    93.000000  \n",
       "mean    228.872093  \n",
       "std     147.779712  \n",
       "min     -52.000000  \n",
       "25%      95.000000  \n",
       "50%     228.872093  \n",
       "75%     324.000000  \n",
       "max     748.000000  \n",
       "\n",
       "[8 rows x 103 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [column_groupby]\n",
    "# columns = columns + columns_corr + other_columns\n",
    "# print(columns)\n",
    "new_X_train = X_train.merge(df_agg, how='left', on=column_groupby)[all_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_agg.columns:\n",
    "    new_X_train[column] = new_X_train[column].fillna(df_agg[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in other_columns:\n",
    "    new_X_train[column] = new_X_train[column].fillna(new_X_train[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3960"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train.isna().sum()\n",
    "len(new_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = new_X_train.select_dtypes(include='number')\n",
    "correlation_matrix = new_df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>Median_FGC-FGC_CU</th>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <th>Min_Physical-Diastolic_BP</th>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <th>Median_BIA-BIA_BMC</th>\n",
       "      <th>Min_BIA-BIA_BMI</th>\n",
       "      <th>Mean_Basic_Demos-Age</th>\n",
       "      <th>Sum_Basic_Demos-Sex</th>\n",
       "      <th>Sum_stat_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum_stat_86</th>\n",
       "      <th>Sum_stat_87</th>\n",
       "      <th>Sum_stat_88</th>\n",
       "      <th>Sum_stat_89</th>\n",
       "      <th>Sum_stat_90</th>\n",
       "      <th>Sum_stat_91</th>\n",
       "      <th>Sum_stat_92</th>\n",
       "      <th>Sum_stat_93</th>\n",
       "      <th>Sum_stat_94</th>\n",
       "      <th>Max_stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798315</td>\n",
       "      <td>0.602366</td>\n",
       "      <td>0.533076</td>\n",
       "      <td>0.755443</td>\n",
       "      <td>0.760010</td>\n",
       "      <td>0.589979</td>\n",
       "      <td>0.923471</td>\n",
       "      <td>-0.629401</td>\n",
       "      <td>-0.599283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595005</td>\n",
       "      <td>-0.597530</td>\n",
       "      <td>-0.596870</td>\n",
       "      <td>-0.595407</td>\n",
       "      <td>-0.600774</td>\n",
       "      <td>-0.597713</td>\n",
       "      <td>-0.597687</td>\n",
       "      <td>-0.597533</td>\n",
       "      <td>-0.595960</td>\n",
       "      <td>-0.635659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median_FGC-FGC_CU</th>\n",
       "      <td>0.798315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675867</td>\n",
       "      <td>0.747832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820947</td>\n",
       "      <td>-0.517403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <td>0.602366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619203</td>\n",
       "      <td>0.516170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.621598</td>\n",
       "      <td>-0.681920</td>\n",
       "      <td>-0.676105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674326</td>\n",
       "      <td>-0.677276</td>\n",
       "      <td>-0.677929</td>\n",
       "      <td>-0.661836</td>\n",
       "      <td>-0.675657</td>\n",
       "      <td>-0.678382</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.678050</td>\n",
       "      <td>-0.679676</td>\n",
       "      <td>-0.662929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Physical-Diastolic_BP</th>\n",
       "      <td>0.533076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522276</td>\n",
       "      <td>-0.532994</td>\n",
       "      <td>-0.538220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.532851</td>\n",
       "      <td>-0.535288</td>\n",
       "      <td>-0.536920</td>\n",
       "      <td>-0.533278</td>\n",
       "      <td>-0.537657</td>\n",
       "      <td>-0.537475</td>\n",
       "      <td>-0.537161</td>\n",
       "      <td>-0.536607</td>\n",
       "      <td>-0.535490</td>\n",
       "      <td>-0.533781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <td>0.755443</td>\n",
       "      <td>0.675867</td>\n",
       "      <td>0.516170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670244</td>\n",
       "      <td>0.619822</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_stat_91</th>\n",
       "      <td>-0.597713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.678382</td>\n",
       "      <td>-0.537475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.506546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.630456</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.998885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.999387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.850744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_stat_92</th>\n",
       "      <td>-0.597687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.537161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.506617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.630570</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.998888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.998994</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.995597</td>\n",
       "      <td>0.999399</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0.850349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_stat_93</th>\n",
       "      <td>-0.597533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.678050</td>\n",
       "      <td>-0.536607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.506953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.630855</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.995749</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.849968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_stat_94</th>\n",
       "      <td>-0.595960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.679676</td>\n",
       "      <td>-0.535490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.505341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.629893</td>\n",
       "      <td>0.991099</td>\n",
       "      <td>0.997773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>0.998694</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>0.993940</td>\n",
       "      <td>0.998624</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_stat_95</th>\n",
       "      <td>-0.635659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.662929</td>\n",
       "      <td>-0.533781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.534755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.621386</td>\n",
       "      <td>0.835953</td>\n",
       "      <td>0.847476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847713</td>\n",
       "      <td>0.846344</td>\n",
       "      <td>0.849874</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.850044</td>\n",
       "      <td>0.850744</td>\n",
       "      <td>0.850349</td>\n",
       "      <td>0.849968</td>\n",
       "      <td>0.849489</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PCIAT-PCIAT_Total  Median_FGC-FGC_CU  \\\n",
       "PCIAT-PCIAT_Total                   1.000000           0.798315   \n",
       "Median_FGC-FGC_CU                   0.798315           1.000000   \n",
       "Min_Physical-Systolic_BP            0.602366                NaN   \n",
       "Min_Physical-Diastolic_BP           0.533076                NaN   \n",
       "Median_Physical-BMI                 0.755443           0.675867   \n",
       "...                                      ...                ...   \n",
       "Sum_stat_91                        -0.597713                NaN   \n",
       "Sum_stat_92                        -0.597687                NaN   \n",
       "Sum_stat_93                        -0.597533                NaN   \n",
       "Sum_stat_94                        -0.595960                NaN   \n",
       "Max_stat_95                        -0.635659                NaN   \n",
       "\n",
       "                           Min_Physical-Systolic_BP  \\\n",
       "PCIAT-PCIAT_Total                          0.602366   \n",
       "Median_FGC-FGC_CU                               NaN   \n",
       "Min_Physical-Systolic_BP                   1.000000   \n",
       "Min_Physical-Diastolic_BP                  0.619203   \n",
       "Median_Physical-BMI                        0.516170   \n",
       "...                                             ...   \n",
       "Sum_stat_91                               -0.678382   \n",
       "Sum_stat_92                               -0.678067   \n",
       "Sum_stat_93                               -0.678050   \n",
       "Sum_stat_94                               -0.679676   \n",
       "Max_stat_95                               -0.662929   \n",
       "\n",
       "                           Min_Physical-Diastolic_BP  Median_Physical-BMI  \\\n",
       "PCIAT-PCIAT_Total                           0.533076             0.755443   \n",
       "Median_FGC-FGC_CU                                NaN             0.675867   \n",
       "Min_Physical-Systolic_BP                    0.619203             0.516170   \n",
       "Min_Physical-Diastolic_BP                   1.000000                  NaN   \n",
       "Median_Physical-BMI                              NaN             1.000000   \n",
       "...                                              ...                  ...   \n",
       "Sum_stat_91                                -0.537475                  NaN   \n",
       "Sum_stat_92                                -0.537161                  NaN   \n",
       "Sum_stat_93                                -0.536607                  NaN   \n",
       "Sum_stat_94                                -0.535490                  NaN   \n",
       "Max_stat_95                                -0.533781                  NaN   \n",
       "\n",
       "                           Median_BIA-BIA_BMC  Min_BIA-BIA_BMI  \\\n",
       "PCIAT-PCIAT_Total                    0.760010         0.589979   \n",
       "Median_FGC-FGC_CU                    0.747832              NaN   \n",
       "Min_Physical-Systolic_BP                  NaN              NaN   \n",
       "Min_Physical-Diastolic_BP                 NaN              NaN   \n",
       "Median_Physical-BMI                  0.670244         0.619822   \n",
       "...                                       ...              ...   \n",
       "Sum_stat_91                         -0.506546              NaN   \n",
       "Sum_stat_92                         -0.506617              NaN   \n",
       "Sum_stat_93                         -0.506953              NaN   \n",
       "Sum_stat_94                         -0.505341              NaN   \n",
       "Max_stat_95                         -0.534755              NaN   \n",
       "\n",
       "                           Mean_Basic_Demos-Age  Sum_Basic_Demos-Sex  \\\n",
       "PCIAT-PCIAT_Total                      0.923471            -0.629401   \n",
       "Median_FGC-FGC_CU                      0.820947            -0.517403   \n",
       "Min_Physical-Systolic_BP               0.621598            -0.681920   \n",
       "Min_Physical-Diastolic_BP              0.522276            -0.532994   \n",
       "Median_Physical-BMI                    0.808789                  NaN   \n",
       "...                                         ...                  ...   \n",
       "Sum_stat_91                           -0.630456             0.992444   \n",
       "Sum_stat_92                           -0.630570             0.992453   \n",
       "Sum_stat_93                           -0.630855             0.992535   \n",
       "Sum_stat_94                           -0.629893             0.991099   \n",
       "Max_stat_95                           -0.621386             0.835953   \n",
       "\n",
       "                           Sum_stat_0  ...  Sum_stat_86  Sum_stat_87  \\\n",
       "PCIAT-PCIAT_Total           -0.599283  ...    -0.595005    -0.597530   \n",
       "Median_FGC-FGC_CU                 NaN  ...          NaN          NaN   \n",
       "Min_Physical-Systolic_BP    -0.676105  ...    -0.674326    -0.677276   \n",
       "Min_Physical-Diastolic_BP   -0.538220  ...    -0.532851    -0.535288   \n",
       "Median_Physical-BMI               NaN  ...          NaN          NaN   \n",
       "...                               ...  ...          ...          ...   \n",
       "Sum_stat_91                  0.998885  ...     0.998923     0.998970   \n",
       "Sum_stat_92                  0.998888  ...     0.998935     0.998994   \n",
       "Sum_stat_93                  0.999002  ...     0.998925     0.998956   \n",
       "Sum_stat_94                  0.997773  ...     0.998542     0.998694   \n",
       "Max_stat_95                  0.847476  ...     0.847713     0.846344   \n",
       "\n",
       "                           Sum_stat_88  Sum_stat_89  Sum_stat_90  Sum_stat_91  \\\n",
       "PCIAT-PCIAT_Total            -0.596870    -0.595407    -0.600774    -0.597713   \n",
       "Median_FGC-FGC_CU                  NaN          NaN          NaN          NaN   \n",
       "Min_Physical-Systolic_BP     -0.677929    -0.661836    -0.675657    -0.678382   \n",
       "Min_Physical-Diastolic_BP    -0.536920    -0.533278    -0.537657    -0.537475   \n",
       "Median_Physical-BMI                NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "Sum_stat_91                   0.999985     0.995604     0.999387     1.000000   \n",
       "Sum_stat_92                   0.999989     0.995597     0.999399     0.999996   \n",
       "Sum_stat_93                   0.999970     0.995749     0.999378     0.999977   \n",
       "Sum_stat_94                   0.999179     0.993940     0.998624     0.999181   \n",
       "Max_stat_95                   0.849874     0.844238     0.850044     0.850744   \n",
       "\n",
       "                           Sum_stat_92  Sum_stat_93  Sum_stat_94  Max_stat_95  \n",
       "PCIAT-PCIAT_Total            -0.597687    -0.597533    -0.595960    -0.635659  \n",
       "Median_FGC-FGC_CU                  NaN          NaN          NaN          NaN  \n",
       "Min_Physical-Systolic_BP     -0.678067    -0.678050    -0.679676    -0.662929  \n",
       "Min_Physical-Diastolic_BP    -0.537161    -0.536607    -0.535490    -0.533781  \n",
       "Median_Physical-BMI                NaN          NaN          NaN          NaN  \n",
       "...                                ...          ...          ...          ...  \n",
       "Sum_stat_91                   0.999996     0.999977     0.999181     0.850744  \n",
       "Sum_stat_92                   1.000000     0.999981     0.999201     0.850349  \n",
       "Sum_stat_93                   0.999981     1.000000     0.999165     0.849968  \n",
       "Sum_stat_94                   0.999201     0.999165     1.000000     0.849489  \n",
       "Max_stat_95                   0.850349     0.849968     0.849489     1.000000  \n",
       "\n",
       "[103 rows x 103 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix[(correlation_matrix > 0.5) | (correlation_matrix < -0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.to_excel('corr_matrix_05.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.concat([new_X_train, y_train], axis=1)\n",
    "df = df[df['sii'].notna()]\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['sii']\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.7859625544937582\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train_split, y_train_split)\n",
    "test_score = reg.score(X_test_split, y_test_split)\n",
    "print(f'Test Score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_indexes = y_train[y_train.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_null = new_X_train.iloc[null_indexes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_null) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 1224.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([0.61999809, 0.71999809, 0.81999809, 0.91999809, 1.01999809,\n",
       "        1.11999809, 1.21999809, 1.31999809, 1.41999809, 1.51999809,\n",
       "        1.61999809]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.iloc[null_indexes] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.round(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_X_train.drop(columns=column_groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Train QWK Score: 0.8117190184832834\n",
      "Validation QWK Score: 0.7969554714917279\n",
      "\n",
      "Model: Ridge\n",
      "Train QWK Score: 0.5934244856975064\n",
      "Validation QWK Score: 0.5969253017133033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mariana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.104e+02, tolerance: 1.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso\n",
      "Train QWK Score: 0.4753403252803391\n",
      "Validation QWK Score: 0.46815042210283964\n",
      "\n",
      "Model: ElasticNet\n",
      "Train QWK Score: 0.7052051488364381\n",
      "Validation QWK Score: 0.7071813801724189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mariana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.501e+02, tolerance: 1.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': {'Train QWK Score': np.float64(0.8117190184832834),\n",
       "  'Validation QWK Score': np.float64(0.7969554714917279)},\n",
       " 'Ridge': {'Train QWK Score': np.float64(0.5934244856975064),\n",
       "  'Validation QWK Score': np.float64(0.5969253017133033)},\n",
       " 'Lasso': {'Train QWK Score': np.float64(0.4753403252803391),\n",
       "  'Validation QWK Score': np.float64(0.46815042210283964)},\n",
       " 'ElasticNet': {'Train QWK Score': np.float64(0.7052051488364381),\n",
       "  'Validation QWK Score': np.float64(0.7071813801724189)}}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_linear_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_tree_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_X_train, local_X_test, local_y_train, local_y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_2 = LinearRegression()\n",
    "reg_2.fit(local_X_train, local_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_FGC-FGC_CU</th>\n",
       "      <th>Min_Physical-Systolic_BP</th>\n",
       "      <th>Min_Physical-Diastolic_BP</th>\n",
       "      <th>Median_Physical-BMI</th>\n",
       "      <th>Median_BIA-BIA_BMC</th>\n",
       "      <th>Min_BIA-BIA_BMI</th>\n",
       "      <th>Mean_Basic_Demos-Age</th>\n",
       "      <th>Sum_Basic_Demos-Sex</th>\n",
       "      <th>Sum_stat_0</th>\n",
       "      <th>Sum_stat_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum_stat_86</th>\n",
       "      <th>Sum_stat_87</th>\n",
       "      <th>Sum_stat_88</th>\n",
       "      <th>Sum_stat_89</th>\n",
       "      <th>Sum_stat_90</th>\n",
       "      <th>Sum_stat_91</th>\n",
       "      <th>Sum_stat_92</th>\n",
       "      <th>Sum_stat_93</th>\n",
       "      <th>Sum_stat_94</th>\n",
       "      <th>Max_stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>17.677979</td>\n",
       "      <td>4.255510</td>\n",
       "      <td>16.238800</td>\n",
       "      <td>12.588235</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.255184e+06</td>\n",
       "      <td>2.255184e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.238340</td>\n",
       "      <td>19.461450</td>\n",
       "      <td>620.294266</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14897.683472</td>\n",
       "      <td>29180.000000</td>\n",
       "      <td>6.047650e+14</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>16.384381</td>\n",
       "      <td>3.107800</td>\n",
       "      <td>12.636700</td>\n",
       "      <td>7.881789</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>3.579265e+07</td>\n",
       "      <td>3.579265e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>240.069235</td>\n",
       "      <td>468.019582</td>\n",
       "      <td>10430.769112</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>276951.082718</td>\n",
       "      <td>488469.416504</td>\n",
       "      <td>1.008740e+16</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>17.093043</td>\n",
       "      <td>3.765365</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>10.187500</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>5.873187e+06</td>\n",
       "      <td>5.873187e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>30.508528</td>\n",
       "      <td>59.678184</td>\n",
       "      <td>1429.152367</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38950.733154</td>\n",
       "      <td>66873.000000</td>\n",
       "      <td>1.382320e+15</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>20.170728</td>\n",
       "      <td>4.714730</td>\n",
       "      <td>13.201600</td>\n",
       "      <td>11.805556</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>3.553243e+06</td>\n",
       "      <td>3.553243e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>30.614478</td>\n",
       "      <td>52.840581</td>\n",
       "      <td>1163.117912</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>27343.783142</td>\n",
       "      <td>54364.500000</td>\n",
       "      <td>1.122750e+15</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.445055</td>\n",
       "      <td>94.763441</td>\n",
       "      <td>50.55914</td>\n",
       "      <td>19.788974</td>\n",
       "      <td>4.494338</td>\n",
       "      <td>15.568655</td>\n",
       "      <td>11.476051</td>\n",
       "      <td>10.72043</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>20.087548</td>\n",
       "      <td>39.349031</td>\n",
       "      <td>951.964441</td>\n",
       "      <td>6.967742</td>\n",
       "      <td>25014.088152</td>\n",
       "      <td>44767.760758</td>\n",
       "      <td>9.241359e+14</td>\n",
       "      <td>74.258065</td>\n",
       "      <td>28.010753</td>\n",
       "      <td>228.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>17.631067</td>\n",
       "      <td>4.087070</td>\n",
       "      <td>11.434000</td>\n",
       "      <td>10.875000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.579147e+06</td>\n",
       "      <td>3.579147e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>21.076339</td>\n",
       "      <td>35.878238</td>\n",
       "      <td>977.225891</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>25873.299988</td>\n",
       "      <td>45924.000000</td>\n",
       "      <td>9.496500e+14</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>12.445055</td>\n",
       "      <td>94.763441</td>\n",
       "      <td>50.55914</td>\n",
       "      <td>19.788974</td>\n",
       "      <td>4.494338</td>\n",
       "      <td>15.568655</td>\n",
       "      <td>11.476051</td>\n",
       "      <td>10.72043</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>20.087548</td>\n",
       "      <td>39.349031</td>\n",
       "      <td>951.964441</td>\n",
       "      <td>6.967742</td>\n",
       "      <td>25014.088152</td>\n",
       "      <td>44767.760758</td>\n",
       "      <td>9.241359e+14</td>\n",
       "      <td>74.258065</td>\n",
       "      <td>28.010753</td>\n",
       "      <td>228.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>19.406721</td>\n",
       "      <td>4.669360</td>\n",
       "      <td>12.654100</td>\n",
       "      <td>11.492308</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>8.362262e+06</td>\n",
       "      <td>8.362262e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>51.230740</td>\n",
       "      <td>89.045863</td>\n",
       "      <td>2305.961311</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>61661.349945</td>\n",
       "      <td>110518.000000</td>\n",
       "      <td>2.246205e+15</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>53.00000</td>\n",
       "      <td>16.779041</td>\n",
       "      <td>3.195550</td>\n",
       "      <td>12.237200</td>\n",
       "      <td>9.511111</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>5.734846e+06</td>\n",
       "      <td>5.734846e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>30.398354</td>\n",
       "      <td>59.350381</td>\n",
       "      <td>1605.652397</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>41157.449890</td>\n",
       "      <td>75201.000000</td>\n",
       "      <td>1.554580e+15</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>12.445055</td>\n",
       "      <td>94.763441</td>\n",
       "      <td>50.55914</td>\n",
       "      <td>19.788974</td>\n",
       "      <td>4.494338</td>\n",
       "      <td>15.568655</td>\n",
       "      <td>11.476051</td>\n",
       "      <td>10.72043</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>3.382464e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>20.087548</td>\n",
       "      <td>39.349031</td>\n",
       "      <td>951.964441</td>\n",
       "      <td>6.967742</td>\n",
       "      <td>25014.088152</td>\n",
       "      <td>44767.760758</td>\n",
       "      <td>9.241359e+14</td>\n",
       "      <td>74.258065</td>\n",
       "      <td>28.010753</td>\n",
       "      <td>228.872093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Median_FGC-FGC_CU  Min_Physical-Systolic_BP  Min_Physical-Diastolic_BP  \\\n",
       "0             10.500000                 93.000000                   55.00000   \n",
       "1              5.000000                 62.000000                   34.00000   \n",
       "2             10.000000                 85.000000                   39.00000   \n",
       "3             14.000000                 94.000000                   44.00000   \n",
       "4             12.445055                 94.763441                   50.55914   \n",
       "...                 ...                       ...                        ...   \n",
       "3955          12.000000                 97.000000                   48.00000   \n",
       "3956          12.445055                 94.763441                   50.55914   \n",
       "3957          11.000000                 98.000000                   42.00000   \n",
       "3958          10.000000                 87.000000                   53.00000   \n",
       "3959          12.445055                 94.763441                   50.55914   \n",
       "\n",
       "      Median_Physical-BMI  Median_BIA-BIA_BMC  Min_BIA-BIA_BMI  \\\n",
       "0               17.677979            4.255510        16.238800   \n",
       "1               16.384381            3.107800        12.636700   \n",
       "2               17.093043            3.765365        13.470000   \n",
       "3               20.170728            4.714730        13.201600   \n",
       "4               19.788974            4.494338        15.568655   \n",
       "...                   ...                 ...              ...   \n",
       "3955            17.631067            4.087070        11.434000   \n",
       "3956            19.788974            4.494338        15.568655   \n",
       "3957            19.406721            4.669360        12.654100   \n",
       "3958            16.779041            3.195550        12.237200   \n",
       "3959            19.788974            4.494338        15.568655   \n",
       "\n",
       "      Mean_Basic_Demos-Age  Sum_Basic_Demos-Sex    Sum_stat_0    Sum_stat_1  \\\n",
       "0                12.588235              3.00000  2.255184e+06  2.255184e+06   \n",
       "1                 7.881789            116.00000  3.579265e+07  3.579265e+07   \n",
       "2                10.187500             19.00000  5.873187e+06  5.873187e+06   \n",
       "3                11.805556             11.00000  3.553243e+06  3.553243e+06   \n",
       "4                11.476051             10.72043  3.382464e+06  3.382464e+06   \n",
       "...                    ...                  ...           ...           ...   \n",
       "3955             10.875000             14.00000  3.579147e+06  3.579147e+06   \n",
       "3956             11.476051             10.72043  3.382464e+06  3.382464e+06   \n",
       "3957             11.492308             28.00000  8.362262e+06  8.362262e+06   \n",
       "3958              9.511111             23.00000  5.734846e+06  5.734846e+06   \n",
       "3959             11.476051             10.72043  3.382464e+06  3.382464e+06   \n",
       "\n",
       "      ...  Sum_stat_86  Sum_stat_87   Sum_stat_88  Sum_stat_89    Sum_stat_90  \\\n",
       "0     ...     9.238340    19.461450    620.294266     6.000000   14897.683472   \n",
       "1     ...   240.069235   468.019582  10430.769112    68.000000  276951.082718   \n",
       "2     ...    30.508528    59.678184   1429.152367    14.000000   38950.733154   \n",
       "3     ...    30.614478    52.840581   1163.117912     8.000000   27343.783142   \n",
       "4     ...    20.087548    39.349031    951.964441     6.967742   25014.088152   \n",
       "...   ...          ...          ...           ...          ...            ...   \n",
       "3955  ...    21.076339    35.878238    977.225891     7.000000   25873.299988   \n",
       "3956  ...    20.087548    39.349031    951.964441     6.967742   25014.088152   \n",
       "3957  ...    51.230740    89.045863   2305.961311    19.000000   61661.349945   \n",
       "3958  ...    30.398354    59.350381   1605.652397    13.000000   41157.449890   \n",
       "3959  ...    20.087548    39.349031    951.964441     6.967742   25014.088152   \n",
       "\n",
       "        Sum_stat_91   Sum_stat_92  Sum_stat_93  Sum_stat_94  Max_stat_95  \n",
       "0      29180.000000  6.047650e+14    46.000000    19.000000   198.000000  \n",
       "1     488469.416504  1.008740e+16   811.000000   316.000000   748.000000  \n",
       "2      66873.000000  1.382320e+15   112.000000    38.000000   332.000000  \n",
       "3      54364.500000  1.122750e+15    91.000000    33.000000   271.000000  \n",
       "4      44767.760758  9.241359e+14    74.258065    28.010753   228.872093  \n",
       "...             ...           ...          ...          ...          ...  \n",
       "3955   45924.000000  9.496500e+14    77.000000    27.000000   276.000000  \n",
       "3956   44767.760758  9.241359e+14    74.258065    28.010753   228.872093  \n",
       "3957  110518.000000  2.246205e+15   179.000000    64.000000   435.000000  \n",
       "3958   75201.000000  1.554580e+15   126.000000    49.000000   324.000000  \n",
       "3959   44767.760758  9.241359e+14    74.258065    28.010753   228.872093  \n",
       "\n",
       "[3960 rows x 102 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6979122551599705"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_2.score(local_X_test, local_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_y_pred = reg_2.predict(local_X_test)\n",
    "local_y_train_pred = reg_2.predict(local_X_train)\n",
    "\n",
    "# conditions = [local_y_pred <= 0, local_y_pred <= 1, local_y_pred <= 2, local_y_pred <= 3]\n",
    "# choices = [0, 1, 2, 3]\n",
    "# local_y_pred = np.select(conditions, choices, default=1)\n",
    "\n",
    "local_y_pred = np.round(local_y_pred).astype(int)\n",
    "local_y_train_pred = np.round(local_y_train_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train QWK Score: 0.7949175265914881\n",
      "Validation QWK Score: 0.8154700107930308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "qwk_score_train = cohen_kappa_score(local_y_train, local_y_train_pred, weights='quadratic')\n",
    "qwk_score_val = cohen_kappa_score(local_y_test, local_y_pred, weights='quadratic')\n",
    "print(\"Train QWK Score:\", qwk_score_train)\n",
    "print(\"Validation QWK Score:\", qwk_score_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suponha que você tenha um DataFrame `train` e `test`, e a coluna `target` contém a variável alvo\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Treino\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='sii', data=pd.DataFrame(local_y_train))\n",
    "plt.title('Distribuição das Classes - Treino')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "# Teste\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='sii', data=pd.DataFrame(local_y_test))\n",
    "plt.title('Distribuição das Classes - Teste')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in columns_corr:\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     # Treino\n",
    "#     sns.kdeplot(local_X_train[column], label='Treino', color='blue')\n",
    "#     sns.kdeplot(local_X_test[column], label='Teste', color='red')\n",
    "#     plt.title(f'Distribuição {column} - Treino vs Teste')\n",
    "#     plt.xlabel('Valores da Feature')\n",
    "#     plt.ylabel('Densidade')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PCIAT-PCIAT_Total',\n",
       " 'Median_FGC-FGC_CU',\n",
       " 'Min_Physical-Systolic_BP',\n",
       " 'Min_Physical-Diastolic_BP',\n",
       " 'Median_Physical-BMI',\n",
       " 'Median_BIA-BIA_BMC',\n",
       " 'Min_BIA-BIA_BMI',\n",
       " 'Mean_Basic_Demos-Age',\n",
       " 'Sum_Basic_Demos-Sex',\n",
       " 'Sum_stat_0',\n",
       " 'Sum_stat_1',\n",
       " 'Sum_stat_2',\n",
       " 'Sum_stat_3',\n",
       " 'Sum_stat_4',\n",
       " 'Sum_stat_5',\n",
       " 'Sum_stat_6',\n",
       " 'Sum_stat_7',\n",
       " 'Sum_stat_8',\n",
       " 'Sum_stat_9',\n",
       " 'Sum_stat_10',\n",
       " 'Sum_stat_11',\n",
       " 'Max_stat_12',\n",
       " 'Min_stat_13',\n",
       " 'Sum_stat_14',\n",
       " 'Max_stat_15',\n",
       " 'Sum_stat_16',\n",
       " 'Sum_stat_17',\n",
       " 'Sum_stat_18',\n",
       " 'Sum_stat_19',\n",
       " 'Sum_stat_20',\n",
       " 'Sum_stat_21',\n",
       " 'Sum_stat_22',\n",
       " 'Max_stat_23',\n",
       " 'Max_stat_24',\n",
       " 'Sum_stat_25',\n",
       " 'Sum_stat_26',\n",
       " 'Max_stat_27',\n",
       " 'Sum_stat_28',\n",
       " 'Sum_stat_29',\n",
       " 'Sum_stat_30',\n",
       " 'Sum_stat_31',\n",
       " 'Sum_stat_32',\n",
       " 'Sum_stat_33',\n",
       " 'Sum_stat_34',\n",
       " 'Sum_stat_35',\n",
       " 'Sum_stat_36',\n",
       " 'Min_stat_37',\n",
       " 'Sum_stat_38',\n",
       " 'Mean_stat_39',\n",
       " 'Sum_stat_40',\n",
       " 'Sum_stat_43',\n",
       " 'Sum_stat_44',\n",
       " 'Sum_stat_45',\n",
       " 'Sum_stat_46',\n",
       " 'Max_stat_47',\n",
       " 'Sum_stat_48',\n",
       " 'Sum_stat_49',\n",
       " 'Sum_stat_50',\n",
       " 'Sum_stat_51',\n",
       " 'Sum_stat_52',\n",
       " 'Sum_stat_53',\n",
       " 'Sum_stat_54',\n",
       " 'Sum_stat_55',\n",
       " 'Sum_stat_56',\n",
       " 'Sum_stat_57',\n",
       " 'Sum_stat_58',\n",
       " 'Max_stat_59',\n",
       " 'Max_stat_60',\n",
       " 'Min_stat_61',\n",
       " 'Sum_stat_62',\n",
       " 'Max_stat_63',\n",
       " 'Sum_stat_64',\n",
       " 'Sum_stat_65',\n",
       " 'Sum_stat_66',\n",
       " 'Sum_stat_67',\n",
       " 'Sum_stat_68',\n",
       " 'Sum_stat_69',\n",
       " 'Sum_stat_70',\n",
       " 'Max_stat_71',\n",
       " 'Max_stat_72',\n",
       " 'Sum_stat_73',\n",
       " 'Sum_stat_74',\n",
       " 'Max_stat_75',\n",
       " 'Sum_stat_76',\n",
       " 'Sum_stat_77',\n",
       " 'Sum_stat_78',\n",
       " 'Sum_stat_79',\n",
       " 'Sum_stat_80',\n",
       " 'Sum_stat_81',\n",
       " 'Sum_stat_82',\n",
       " 'Max_stat_83',\n",
       " 'Sum_stat_84',\n",
       " 'Sum_stat_85',\n",
       " 'Sum_stat_86',\n",
       " 'Sum_stat_87',\n",
       " 'Sum_stat_88',\n",
       " 'Sum_stat_89',\n",
       " 'Sum_stat_90',\n",
       " 'Sum_stat_91',\n",
       " 'Sum_stat_92',\n",
       " 'Sum_stat_93',\n",
       " 'Sum_stat_94',\n",
       " 'Max_stat_95']"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FGC-FGC_CU',\n",
       " 'Physical-Systolic_BP',\n",
       " 'Physical-Diastolic_BP',\n",
       " 'Physical-BMI',\n",
       " 'BIA-BIA_BMC',\n",
       " 'BIA-BIA_BMI',\n",
       " 'Basic_Demos-Age',\n",
       " 'Basic_Demos-Sex',\n",
       " 'stat_0',\n",
       " 'stat_1',\n",
       " 'stat_2',\n",
       " 'stat_3',\n",
       " 'stat_4',\n",
       " 'stat_5',\n",
       " 'stat_6',\n",
       " 'stat_7',\n",
       " 'stat_8',\n",
       " 'stat_9',\n",
       " 'stat_10',\n",
       " 'stat_11',\n",
       " 'stat_12',\n",
       " 'stat_13',\n",
       " 'stat_14',\n",
       " 'stat_15',\n",
       " 'stat_16',\n",
       " 'stat_17',\n",
       " 'stat_18',\n",
       " 'stat_19',\n",
       " 'stat_20',\n",
       " 'stat_21',\n",
       " 'stat_22',\n",
       " 'stat_23',\n",
       " 'stat_24',\n",
       " 'stat_25',\n",
       " 'stat_26',\n",
       " 'stat_27',\n",
       " 'stat_28',\n",
       " 'stat_29',\n",
       " 'stat_30',\n",
       " 'stat_31',\n",
       " 'stat_32',\n",
       " 'stat_33',\n",
       " 'stat_34',\n",
       " 'stat_35',\n",
       " 'stat_36',\n",
       " 'stat_37',\n",
       " 'stat_38',\n",
       " 'stat_39',\n",
       " 'stat_40',\n",
       " 'stat_41',\n",
       " 'stat_42',\n",
       " 'stat_43',\n",
       " 'stat_44',\n",
       " 'stat_45',\n",
       " 'stat_46',\n",
       " 'stat_47',\n",
       " 'stat_48',\n",
       " 'stat_49',\n",
       " 'stat_50',\n",
       " 'stat_51',\n",
       " 'stat_52',\n",
       " 'stat_53',\n",
       " 'stat_54',\n",
       " 'stat_55',\n",
       " 'stat_56',\n",
       " 'stat_57',\n",
       " 'stat_58',\n",
       " 'stat_59',\n",
       " 'stat_60',\n",
       " 'stat_61',\n",
       " 'stat_62',\n",
       " 'stat_63',\n",
       " 'stat_64',\n",
       " 'stat_65',\n",
       " 'stat_66',\n",
       " 'stat_67',\n",
       " 'stat_68',\n",
       " 'stat_69',\n",
       " 'stat_70',\n",
       " 'stat_71',\n",
       " 'stat_72',\n",
       " 'stat_73',\n",
       " 'stat_74',\n",
       " 'stat_75',\n",
       " 'stat_76',\n",
       " 'stat_77',\n",
       " 'stat_78',\n",
       " 'stat_79',\n",
       " 'stat_80',\n",
       " 'stat_81',\n",
       " 'stat_82',\n",
       " 'stat_83',\n",
       " 'stat_84',\n",
       " 'stat_85',\n",
       " 'stat_86',\n",
       " 'stat_87',\n",
       " 'stat_88',\n",
       " 'stat_89',\n",
       " 'stat_90',\n",
       " 'stat_91',\n",
       " 'stat_92',\n",
       " 'stat_93',\n",
       " 'stat_94',\n",
       " 'stat_95']"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_agg\n",
    "# print(columns_agg_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_X_test = X_test.merge(test_series_data_stats, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in other_columns:\n",
    "    merged_data_X_test[column] = merged_data_X_test[column].fillna(new_X_train[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = merged_data_X_test.loc[:, column_agg + other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-385-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-385-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-385-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-385-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
      "<ipython-input-385-4db0297c3fc1>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n"
     ]
    }
   ],
   "source": [
    "for column in column_agg:\n",
    "    index = column_agg.index(column)\n",
    "    if X_test_predict[column].isna().sum() > 0:\n",
    "        try:\n",
    "            X_test_predict[columns_corr[index]] = X_test_predict[column].fillna(df_agg[columns_corr[index]].mean())\n",
    "        except:\n",
    "            print(index)\n",
    "    else:\n",
    "        X_test_predict[columns_corr[index]] = X_test_predict[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = X_test_predict.loc[:, columns_corr + other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = reg_2.predict(X_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40462756e-01, -3.70948390e-02,  1.42614439e+00, -2.51590885e+12,\n",
       "        1.77636077e+00, -2.50719318e+12,  2.27799071e-01,  1.21470223e-01,\n",
       "        1.64159867e+00,  1.83156358e+00,  1.38994104e+00,  1.42078740e+00,\n",
       "        2.31772168e+00,  9.85087987e-01,  1.47599021e+00,  9.36623689e-01,\n",
       "       -1.87387369e-02,  8.70877887e-01,  1.20815668e+00,  1.36558458e+00])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_round = np.round(y_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_round = round_final_results(y_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 2 0 0 0 2 2 1 1 2 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame({'id': X_test['id'], 'sii': y_test_round})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df_y_test.to_csv(f'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    0\n",
       "1   000fd460    0\n",
       "2   00105258    1\n",
       "3   00115b9f    0\n",
       "4   0016bb22    2\n",
       "5   001f3379    0\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    2\n",
       "9   0083e397    2\n",
       "10  0087dd65    1\n",
       "11  00abe655    1\n",
       "12  00ae59c9    2\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    1\n",
       "18  00e6167c    1\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([X_train,y_train], axis=1).to_csv('df_final_to_powerbi_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
